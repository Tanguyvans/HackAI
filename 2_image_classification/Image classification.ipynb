{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# **1. Matériel : vérifier que le GPU est bien sélectionné**"
      ],
      "metadata": {
        "id": "fm0NITKpBrT9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('Not connected to a GPU')\n",
        "else:\n",
        "  print(gpu_info)\n",
        "\n",
        "device = (\n",
        "    \"cuda\"\n",
        "    if torch.cuda.is_available()\n",
        "    else \"mps\"\n",
        "    if torch.backends.mps.is_available()\n",
        "    else \"cpu\"\n",
        ")\n",
        "print(f\"Using {device} device\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 588
        },
        "id": "yOT6M8APBsEh",
        "outputId": "26b6c8c5-9c41-419e-96a0-bf0dbb2391dd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sun May 12 11:34:08 2024       \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 535.104.05             Driver Version: 535.104.05   CUDA Version: 12.2     |\n",
            "|-----------------------------------------+----------------------+----------------------+\n",
            "| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                                         |                      |               MIG M. |\n",
            "|=========================================+======================+======================|\n",
            "|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   39C    P8               9W /  70W |      0MiB / 15360MiB |      0%      Default |\n",
            "|                                         |                      |                  N/A |\n",
            "+-----------------------------------------+----------------------+----------------------+\n",
            "                                                                                         \n",
            "+---------------------------------------------------------------------------------------+\n",
            "| Processes:                                                                            |\n",
            "|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n",
            "|        ID   ID                                                             Usage      |\n",
            "|=======================================================================================|\n",
            "|  No running processes found                                                           |\n",
            "+---------------------------------------------------------------------------------------+\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'torch' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-d0125513e5d0>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m device = (\n\u001b[1;32m      9\u001b[0m     \u001b[0;34m\"cuda\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcuda\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0;32melse\u001b[0m \u001b[0;34m\"mps\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackends\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmps\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_available\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'torch' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2. Importation des librairies**"
      ],
      "metadata": {
        "id": "5iFUpyllB1PC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import sys,os\n",
        "import torch, torchvision\n",
        "#import torchvision.transforms as transforms\n",
        "from torchvision import datasets, transforms\n",
        "import torch.nn as nn\n",
        "from torchsummary import summary\n",
        "\n",
        "from torch import Tensor\n",
        "from functools import partial\n",
        "\n",
        "from torchvision.transforms._presets import ImageClassification\n",
        "import torchvision.models as models\n",
        "from torchvision.models import ResNet50_Weights\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.pyplot import imshow"
      ],
      "metadata": {
        "id": "dF-UdDKMB5W-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3. Importation des données**"
      ],
      "metadata": {
        "id": "cI4t3_2FCfRa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)\n",
        "folder='Gdrive' #@param ['Gdrive']\n",
        "if folder == 'Gdrive' :\n",
        "  image_classification_path = '/content/drive/MyDrive/IA/UMONS/Workshop/2. Image classification'\n",
        "  training_path=   image_classification_path + '/' + 'data'\n",
        "sys.path.append(image_classification_path)\n",
        "os.chdir(image_classification_path)\n"
      ],
      "metadata": {
        "id": "3iiVLa54Ca9X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **4. Paramètres**"
      ],
      "metadata": {
        "id": "RmKtulonbtHq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size=16 #@param [16,32]\n",
        "validation_split = 0.1\n",
        "seed = 50 #@param\n",
        "classifier='ResNet50v2' #@param ['ResNet50v2']\n",
        "#base_model = models.resnet50(pretrained=True)\n",
        "\n",
        "if classifier == 'ResNet50v2':\n",
        "  weights=ResNet50_Weights.DEFAULT\n",
        "  base_model=models.resnet50(weights=weights).to(device)\n",
        "  preprocess = weights.transforms()\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "NqJpJHqlHg94"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **5. Visualiser une image**"
      ],
      "metadata": {
        "id": "dpKgk9g-bwiX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "transformView = transforms.Compose([transforms.Resize(255),\n",
        "                                transforms.CenterCrop(224),\n",
        "                                transforms.ToTensor()\n",
        "                               ])\n",
        "datasetView = datasets.ImageFolder(training_path,transformView)\n",
        "dataloaderView = torch.utils.data.DataLoader(datasetView, batch_size=batch_size, shuffle=True)"
      ],
      "metadata": {
        "id": "5u8_hWNmRjt4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images,labels = next(iter(dataloaderView))\n",
        "imshow(images[0].permute(1, 2, 0))"
      ],
      "metadata": {
        "id": "d-L0qqknS6es"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **6. Visualiser une image préparée pour le modèle de base**"
      ],
      "metadata": {
        "id": "0KcHSJPOb35u"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#ancien\n",
        "\n",
        "from torch.utils.data import DataLoader, Subset\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "dataset = datasets.ImageFolder(training_path,preprocess)\n",
        "\n",
        "# generate indices: instead of the actual data we pass in integers instead\n",
        "#train_indices, valid_indices, _, _ = train_test_split(\n",
        "    #range(len(dataset)),\n",
        "    #dataset.targets,\n",
        "    #stratify=dataset.targets,\n",
        "    #test_size=validation_split,\n",
        "    #random_state=seed\n",
        "#)\n",
        "\n",
        "train_indices, valid_indices, _, _ = train_test_split(\n",
        "    np.arange(dataset.targets),\n",
        "    dataset.targets,\n",
        "    stratify=dataset.targets,\n",
        "    test_size=validation_split,\n",
        "    random_state=seed\n",
        ")\n",
        "\n",
        "# generate subset based on indices\n",
        "train_dataset = Subset(dataset, train_indices)\n",
        "validation_dataset = Subset(dataset, valid_indices)\n",
        "\n",
        "# create batches\n",
        "dataloader={}\n",
        "dataloader['train'] = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
        "dataloader['validation']  = DataLoader(validation_dataset, batch_size=batch_size)"
      ],
      "metadata": {
        "id": "8uLnuWBT68VQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = datasets.ImageFolder(training_path,preprocess)\n",
        "generator1 = torch.Generator().manual_seed(seed)\n",
        "dataloader={}\n",
        "dataset= torch.utils.data.random_split(dataset, [0.8,0.2],generator=generator1)\n",
        "dataset={'train':dataset[0],'validation':dataset[1]}\n",
        "dataloader = {'train':DataLoader(dataset=dataset['train'], shuffle=True, batch_size=batch_size, drop_last=True),\n",
        "                'validation':DataLoader(dataset=dataset['validation'], shuffle=False, batch_size=batch_size)\n",
        "}\n",
        "print(len(dataloader['train']),len(dataloader['validation']))\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "rJmMmu_0toWs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "images,labels = next(iter(dataloader['train']))\n",
        "print(images[0])\n",
        "imshow(images[0].permute(1, 2, 0))\n",
        "#imshow(images[0])\n",
        "print(labels[0])"
      ],
      "metadata": {
        "id": "HcjeEuatZ9vS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **7. Construction du modèle**"
      ],
      "metadata": {
        "id": "tJuRtOI-dZtd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#ancien\n",
        "\n",
        "class Model(nn.Module):\n",
        "  def __init__(self):\n",
        "      super().__init__()\n",
        "      self.base_model = base_model\n",
        "      for param in self.base_model.parameters():\n",
        "        param.requires_grad = False\n",
        "      self.fc = nn.Sequential(\n",
        "            nn.Linear(2048, 1024),\n",
        "            nn.ReLU(inplace=True),\n",
        "            nn.Dropout(p=0.3,inplace=True),\n",
        "            nn.Linear(1024, 3),\n",
        "            nn.Softmax()\n",
        "            )\n",
        "\n",
        "  def forward(self,x):\n",
        "    self.to(device)\n",
        "    x = self.fc(self.base_model(x))\n",
        "    return x\n",
        "\n",
        "model=Model()\n"
      ],
      "metadata": {
        "id": "RjFLtE77UEyV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "del model\n",
        "model=base_model\n",
        "for param in model.parameters():\n",
        "    param.requires_grad = False\n",
        "model.fc = nn.Sequential(\n",
        "              nn.Linear(2048, 1024),\n",
        "              nn.ReLU(inplace=True),\n",
        "              nn.Dropout(p=0.3),\n",
        "              nn.Linear(1024, 3),\n",
        "              nn.Softmax(-1)\n",
        "              )\n",
        "model=model.to(device)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "\n",
        "# Observe that only parameters of final layer are being optimized as\n",
        "# opposed to before.\n",
        "optimizer = torch.optim.SGD(model.fc.parameters(), lr=0.001, momentum=0.9)\n",
        "\n",
        "# Decay LR by a factor of 0.1 every 7 epochs\n",
        "exp_lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n"
      ],
      "metadata": {
        "id": "ioZQ5w9S3oGz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "summary(model, (3, 224, 224))"
      ],
      "metadata": {
        "id": "YRdYfuI_QLCt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(model)"
      ],
      "metadata": {
        "id": "0ajRnLphOYZB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **8. Entraînement du modèle**"
      ],
      "metadata": {
        "id": "tKQCs8B_BDIX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_model(model, criterion, optimizer, scheduler, num_epochs=3):\n",
        "    for epoch in range(num_epochs):\n",
        "        print('Epoch {}/{}'.format(epoch+1, num_epochs))\n",
        "        print('-' * 10)\n",
        "\n",
        "        for phase in ['train', 'validation']:\n",
        "            if phase == 'train':\n",
        "                model.train()\n",
        "            else:\n",
        "                model.eval()\n",
        "\n",
        "            running_loss = 0.0\n",
        "            running_corrects = 0\n",
        "\n",
        "            for inputs, labels in dataloader[phase]:\n",
        "                inputs = inputs.to(device)\n",
        "                labels = labels.to(device)\n",
        "\n",
        "                outputs = model(inputs)\n",
        "                loss = criterion(outputs, labels)\n",
        "\n",
        "                if phase == 'train':\n",
        "                    optimizer.zero_grad()\n",
        "                    loss.backward()\n",
        "                    optimizer.step()\n",
        "\n",
        "                _, preds = torch.max(outputs, 1)\n",
        "                running_loss += loss.item() * inputs.size(0)\n",
        "                running_corrects += torch.sum(preds == labels.data)\n",
        "            if phase == 'train':\n",
        "              scheduler.step()\n",
        "\n",
        "            epoch_loss = running_loss / len(dataset[phase])\n",
        "            epoch_acc = running_corrects.double() / len(dataset[phase])\n",
        "\n",
        "            print('{} loss: {:.4f}, acc: {:.4f}'.format(phase,\n",
        "                                                        epoch_loss,\n",
        "                                                        epoch_acc))\n",
        "    return model"
      ],
      "metadata": {
        "id": "x8Hbr7F14S6o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = train_model(model, criterion, optimizer, exp_lr_scheduler,num_epochs=12)"
      ],
      "metadata": {
        "id": "Rzq98zR3417n"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Brouillon**"
      ],
      "metadata": {
        "id": "IVJ3oV6gS7Xh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#pour avoir la distribution des classes\n",
        "print(dataset.class_to_idx)\n",
        "idx_to_class = {v: k for k, v in dataset.class_to_idx.items()}\n",
        "print(idx_to_class)\n",
        "def get_class_distribution(dataset):\n",
        "    count_dict = {k:0 for k,v in dataset.class_to_idx.items()} # initialise dictionary\n",
        "\n",
        "    for input, label in dataset:\n",
        "        label = idx_to_class[label]\n",
        "        count_dict[label] += 1\n",
        "\n",
        "    return count_dict\n",
        "\n",
        "print(\"Distribution of classes: \", get_class_distribution(dataset))"
      ],
      "metadata": {
        "id": "6SD0lTF4Cer9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Model(nn.Module):\n",
        "  def __init__(self, backbone):\n",
        "      super().__init__()\n",
        "      self.pretrained_model = None\n",
        "      self.classifier_layers = []\n",
        "      self.new_layers = []\n",
        "\n",
        "      self.pretrained_model = base_model\n",
        "      self.classifier_layers = [self.pretrained_model.fc]\n",
        "      self.pretrained_model.fc = nn.Linear(\n",
        "          in_features=2048, out_features=3, bias=True\n",
        "      )\n",
        "      self.pretrained_model.fc = nn.Sequential(\n",
        "          torch.nn.AvgPool2d(kernel_size = 100, stride = 0, padding = 0, ceil_mode=False, count_include_pad=True),\n",
        "          nn.Linear(1024, 512),\n",
        "\n",
        "\n",
        "      out_features=3, bias=True\n",
        "      )\n",
        "      x = torch.nn.AvgPool2d(kernel_size = 100, stride = 0, padding = 0, ceil_mode=False, count_include_pad=True)(x)\n",
        "      self.new_layers = [self.pretrained_model.fc]\n",
        "\n",
        "        self.linear_relu_stack = nn.Sequential(\n",
        "            nn.Linear(28*28, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 512),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(512, 10),\n",
        "        )\n",
        "\n",
        "  def freezing(self):\n",
        "    for p in self.pretrained_model:\n",
        "      p.requires_grad = False\n",
        "    for l in self.new_layers:\n",
        "      for p in l.parameters():\n",
        "          p.requires_grad = True\n",
        "\n",
        "  def get_optimizer_params(self):\n",
        "    \"\"\"This method is used only during model fine-tuning when we need to\n",
        "    set a linearly or exponentially decaying learning rate (LR) for the\n",
        "    layers in the model. We exponentially decay the learning rate as we\n",
        "    move away from the last output layer.\n",
        "    \"\"\"\n",
        "    options = []\n",
        "    # For the resnet class of models, we decay the LR exponentially and reduce\n",
        "    # it to a third of the previous value at each step.\n",
        "    layers = [\"conv1\", \"bn1\", \"layer1\", \"layer2\", \"layer3\", \"layer4\", \"fc\"]\n",
        "    lr = 0.0001\n",
        "    for layer_name in reversed(layers):\n",
        "        options.append(\n",
        "            {\n",
        "                \"params\": getattr(self.pretrained_model, layer_name).parameters(),\n",
        "                \"lr\": lr,\n",
        "            }\n",
        "        )\n",
        "        lr = lr / 3.0\n",
        "    # end for\n",
        "    return options"
      ],
      "metadata": {
        "id": "uyQbQkyojxAf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "optimizer = torch.optim.Adam(fc.get_optimizer_params(), lr=1e-8)"
      ],
      "metadata": {
        "id": "rpafsPvJlg4y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Model(nn.Module):\n",
        "  def __init__(self):\n",
        "    self.conv1 = base_model"
      ],
      "metadata": {
        "id": "WcsxK_dEf3hH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class BasicBlock(nn.Module):\n",
        "    expansion = 1\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1):\n",
        "        super(BasicBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(\n",
        "            in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
        "                               stride=1, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion*planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, self.expansion*planes,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(self.expansion*planes)\n",
        "            )\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = self.bn2(self.conv2(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out\n",
        "\n",
        "class Bottleneck(nn.Module):\n",
        "    expansion = 4\n",
        "\n",
        "    def __init__(self, in_planes, planes, stride=1):\n",
        "        super(Bottleneck, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=1, bias=False)\n",
        "        self.bn1 = nn.BatchNorm2d(planes)\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3,\n",
        "                               stride=stride, padding=1, bias=False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.conv3 = nn.Conv2d(planes, self.expansion *\n",
        "                               planes, kernel_size=1, bias=False)\n",
        "        self.bn3 = nn.BatchNorm2d(self.expansion*planes)\n",
        "\n",
        "        self.shortcut = nn.Sequential()\n",
        "        if stride != 1 or in_planes != self.expansion*planes:\n",
        "            self.shortcut = nn.Sequential(\n",
        "                nn.Conv2d(in_planes, self.expansion*planes,\n",
        "                          kernel_size=1, stride=stride, bias=False),\n",
        "                nn.BatchNorm2d(self.expansion*planes)\n",
        "            )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out = F.relu(self.bn1(self.conv1(x)))\n",
        "        out = F.relu(self.bn2(self.conv2(out)))\n",
        "        out = self.bn3(self.conv3(out))\n",
        "        out += self.shortcut(x)\n",
        "        out = F.relu(out)\n",
        "        return out"
      ],
      "metadata": {
        "id": "tBZGkAezdhXe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = datasets.ImageFolder(training_path,preprocess)\n",
        "dataloaders = {\n",
        "    'train':\n",
        "    torch.utils.data.DataLoader(dataset['train'],\n",
        "                                batch_size=32,\n",
        "                                shuffle=True,\n",
        "                                num_workers=0),  # for Kaggle\n",
        "    'validation':\n",
        "    torch.utils.data.DataLoader(image_datasets['validation'],\n",
        "                                batch_size=32,\n",
        "                                shuffle=False,\n",
        "                                num_workers=0)  # for Kaggle\n",
        "}\n",
        "dataloader = torch.utils.data.DataLoader(dataset, batch_size=batch_size, shuffle=True)"
      ],
      "metadata": {
        "id": "ayji5A9j8VXO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# sample execution (requires torchvision)\n",
        "from PIL import Image\n",
        "from torchvision import transforms\n",
        "input_image = Image.open(filename)\n",
        "preprocess = transforms.Compose([\n",
        "    transforms.Resize(256),\n",
        "    transforms.CenterCrop(224),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
        "])\n",
        "input_tensor = preprocess(input_image)\n",
        "input_batch = input_tensor.unsqueeze(0) # create a mini-batch as expected by the model\n",
        "\n",
        "# move the input and model to GPU for speed if available\n",
        "if torch.cuda.is_available():\n",
        "    input_batch = input_batch.to('cuda')\n",
        "    model.to('cuda')\n",
        "\n",
        "with torch.no_grad():\n",
        "    output = model(input_batch)\n",
        "# Tensor of shape 1000, with confidence scores over ImageNet's 1000 classes\n",
        "print(output[0])\n",
        "# The output has unnormalized scores. To get probabilities, you can run a softmax on it.\n",
        "probabilities = torch.nn.functional.softmax(output[0], dim=0)\n",
        "print(probabilities)"
      ],
      "metadata": {
        "id": "JTA-8vFPY7Ks"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "next(iter(dataloader))"
      ],
      "metadata": {
        "id": "z3g0U5MrTrer"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose(\n",
        "    [transforms.ToTensor(),\n",
        "     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n",
        "\n",
        "batch_size = 4\n",
        "\n",
        "trainset = torchvision.datasets.CIFAR10(root='./data', train=True,\n",
        "                                        download=True, transform=transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size,\n",
        "                                          shuffle=True, num_workers=2)\n",
        "\n",
        "testset = torchvision.datasets.CIFAR10(root='./data', train=False,\n",
        "                                       download=True, transform=transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size,\n",
        "                                         shuffle=False, num_workers=2)\n",
        "\n",
        "classes = ('plane', 'car', 'bird', 'cat',\n",
        "           'deer', 'dog', 'frog', 'horse', 'ship', 'truck')"
      ],
      "metadata": {
        "id": "pTMAHWIAEir_"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}