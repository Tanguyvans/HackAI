{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "GPIqLNzl4nn1"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision\n",
        "import torchvision.datasets as datasets\n",
        "import torchvision.models as models\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import DataLoader, SubsetRandomSampler\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "BTHIsUZPvwl-"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\maxgl\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torchvision\\models\\_utils.py:135: UserWarning: Using 'weights' as positional parameter(s) is deprecated since 0.13 and may be removed in the future. Please use keyword parameter(s) instead.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "ResNet(\n",
            "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (layer1): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (3): Bottleneck(\n",
            "      (conv1): Conv2d(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (3): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (4): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (5): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (layer4): Sequential(\n",
            "    (0): Bottleneck(\n",
            "      (conv1): Conv2d(1024, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(1024, 2048, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): Bottleneck(\n",
            "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "    (2): Bottleneck(\n",
            "      (conv1): Conv2d(2048, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv3): Conv2d(512, 2048, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
            "      (bn3): BatchNorm2d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (fc): Linear(in_features=2048, out_features=1000, bias=True)\n",
            ")\n"
          ]
        }
      ],
      "source": [
        "fireModel = models.resnet50(models.ResNet50_Weights.IMAGENET1K_V1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "AwC2f556xeud"
      },
      "outputs": [],
      "source": [
        "# replace the last layer of the model (called fc in ResNet) -> 3 output classes [\"Fire\" \"NoFire\" \"Start Fire\"]\n",
        "fireModel.fc = nn.Linear(fireModel.fc.in_features, 3) "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "D9_DCg12mDK3"
      },
      "outputs": [],
      "source": [
        "device       = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu') # define the device to use (cuda:0 if the gpu is availble)\n",
        "datasetPath  = \"big\"                                                          # define the path to the dataset (where a folder is a class)\n",
        "batchSize\t = 32                                                             # define the batch size\n",
        "trainSplit   = 0.8                                                            # define the ratio of data to use for training\n",
        "testSplit    = 0.1                                                            # define the ratio of data to use for testing\n",
        "validSplit   = 0.1                                                            # the rest is used for validation\n",
        "epochs\t\t = 100                                                            # define the number of epoch\n",
        "criterion    = nn.CrossEntropyLoss()                                          # define the loss function\n",
        "learnRate\t = 0.01                                                           # define the learning rate\n",
        "optimizer    = optim.Adam(fireModel.parameters(), lr=learnRate)                # define the optimizer\n",
        "imgSize      = 224                                                            # define the input size"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "W62ShA_yWHT-"
      },
      "outputs": [],
      "source": [
        "# Preparing data transformations (composition of transforms)\n",
        "transform   = transforms.Compose([\n",
        "\t\t\t\t\t\t\t\ttransforms.RandomResizedCrop(imgSize),\t# Resize the picture\n",
        "\t\t\t\t\t\t\t\ttransforms.ToTensor()\t\t\t\t\t# Transform the picture as a tensor\n",
        "])\n",
        "# Preparing target (label) transformations (composition of transforms)\n",
        "target_transform = transforms.Compose([\n",
        "\t\t# Only a function that 1) transform an int (label) to a tensor, 2) encode the tensor (one-hot), 3) convert the tensor to float\n",
        "\t\tlambda label: torch.nn.functional.one_hot(torch.tensor( label ), num_classes=3).float()\n",
        "])\n",
        "# Create the dataset based on the path and apply the transformations defined above\n",
        "dataset   = datasets.ImageFolder(\n",
        "\t\t\t\t\t\t\t\t\tdatasetPath,\n",
        "\t\t\t\t\t\t\t\t\ttransform=transform,\n",
        "\t\t\t\t\t\t\t\t\ttarget_transform=target_transform\n",
        ")\n",
        "\n",
        "# Compute the number of pictures that will be used for train, val and test datasets\n",
        "trainlen\t= int(trainSplit * len(dataset))\n",
        "testlen\t\t= int(testSplit  * len(dataset))\n",
        "validlen\t= len(dataset) - trainlen - testlen\n",
        "# Then random split indices of the dataset into subsets: train, valid and test\n",
        "# The results are sampler (dataset indices generator)\n",
        "trainset,validset,testset = torch.utils.data.random_split(range(len(dataset)), [trainlen, validlen, testlen])\n",
        "\n",
        "# create a loader foreach subset based on its sampler with a batch_size\n",
        "trainloader = DataLoader(\n",
        "\t\t\t\t\t\tdataset,\n",
        "\t\t\t\t\t\tbatch_size=batchSize,\n",
        "\t\t\t\t\t\tsampler=torch.utils.data.SubsetRandomSampler(trainset), # Use the SubsetRandomSampler to random indices at each epoch\n",
        ")\n",
        "\n",
        "valloader = DataLoader(\n",
        "\t\t\t\t\t\tdataset,\n",
        "\t\t\t\t\t\tbatch_size=batchSize,\n",
        "\t\t\t\t\t\tsampler=validset\n",
        ")\n",
        "\n",
        "testloader = DataLoader(\n",
        "\t\t\t\t\t\tdataset,\n",
        "\t\t\t\t\t\tbatch_size=batchSize,\n",
        "\t\t\t\t\t\tsampler=testset\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "s4SVrulG3Raa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "train [1] loss: 0.028 accuracy: 74.669%\n",
            "validation [1] loss: 0.017 accuracy: 80.840%\n",
            "train [2] loss: 0.017 accuracy: 79.907%\n",
            "validation [2] loss: 0.015 accuracy: 82.521%\n",
            "train [3] loss: 0.016 accuracy: 80.034%\n",
            "validation [3] loss: 0.014 accuracy: 84.874%\n",
            "train [4] loss: 0.016 accuracy: 80.770%\n",
            "validation [4] loss: 0.017 accuracy: 79.832%\n",
            "train [5] loss: 0.015 accuracy: 82.306%\n",
            "validation [5] loss: 0.014 accuracy: 84.034%\n",
            "train [6] loss: 0.014 accuracy: 82.285%\n",
            "validation [6] loss: 0.014 accuracy: 84.874%\n",
            "train [7] loss: 0.014 accuracy: 83.358%\n",
            "validation [7] loss: 0.017 accuracy: 84.034%\n",
            "train [8] loss: 0.013 accuracy: 83.926%\n",
            "validation [8] loss: 0.014 accuracy: 86.723%\n",
            "train [9] loss: 0.013 accuracy: 84.178%\n",
            "validation [9] loss: 0.012 accuracy: 86.387%\n",
            "train [10] loss: 0.012 accuracy: 85.420%\n",
            "validation [10] loss: 0.014 accuracy: 83.361%\n",
            "train [11] loss: 0.012 accuracy: 85.104%\n",
            "validation [11] loss: 0.019 accuracy: 79.664%\n",
            "train [12] loss: 0.012 accuracy: 85.336%\n",
            "validation [12] loss: 0.015 accuracy: 86.555%\n",
            "train [13] loss: 0.011 accuracy: 86.219%\n",
            "validation [13] loss: 0.011 accuracy: 87.731%\n",
            "train [14] loss: 0.012 accuracy: 85.967%\n",
            "validation [14] loss: 0.016 accuracy: 85.882%\n",
            "train [15] loss: 0.011 accuracy: 87.229%\n",
            "validation [15] loss: 0.012 accuracy: 86.218%\n",
            "train [16] loss: 0.011 accuracy: 87.313%\n",
            "validation [16] loss: 0.011 accuracy: 87.395%\n",
            "train [17] loss: 0.011 accuracy: 87.145%\n",
            "validation [17] loss: 0.010 accuracy: 90.084%\n",
            "train [18] loss: 0.011 accuracy: 86.892%\n",
            "validation [18] loss: 0.010 accuracy: 88.403%\n",
            "train [19] loss: 0.010 accuracy: 87.250%\n",
            "validation [19] loss: 0.010 accuracy: 88.403%\n",
            "train [20] loss: 0.011 accuracy: 87.292%\n",
            "validation [20] loss: 0.012 accuracy: 87.227%\n",
            "train [21] loss: 0.010 accuracy: 88.260%\n",
            "validation [21] loss: 0.010 accuracy: 89.748%\n",
            "train [22] loss: 0.010 accuracy: 88.155%\n",
            "validation [22] loss: 0.010 accuracy: 88.067%\n",
            "train [23] loss: 0.010 accuracy: 88.555%\n",
            "validation [23] loss: 0.011 accuracy: 87.731%\n",
            "train [24] loss: 0.010 accuracy: 87.923%\n",
            "validation [24] loss: 0.009 accuracy: 89.916%\n",
            "train [25] loss: 0.010 accuracy: 88.344%\n",
            "validation [25] loss: 0.010 accuracy: 91.429%\n",
            "train [26] loss: 0.010 accuracy: 88.870%\n",
            "validation [26] loss: 0.010 accuracy: 89.580%\n",
            "train [27] loss: 0.010 accuracy: 88.197%\n",
            "validation [27] loss: 0.011 accuracy: 87.563%\n",
            "train [28] loss: 0.010 accuracy: 87.923%\n",
            "validation [28] loss: 0.012 accuracy: 86.050%\n",
            "train [29] loss: 0.010 accuracy: 88.239%\n",
            "validation [29] loss: 0.011 accuracy: 86.218%\n",
            "train [30] loss: 0.010 accuracy: 88.008%\n",
            "validation [30] loss: 0.010 accuracy: 88.908%\n",
            "train [31] loss: 0.010 accuracy: 88.681%\n",
            "validation [31] loss: 0.011 accuracy: 89.412%\n",
            "train [32] loss: 0.010 accuracy: 88.449%\n",
            "validation [32] loss: 0.008 accuracy: 92.269%\n",
            "train [33] loss: 0.010 accuracy: 88.807%\n",
            "validation [33] loss: 0.010 accuracy: 89.076%\n",
            "train [34] loss: 0.010 accuracy: 87.692%\n",
            "validation [34] loss: 0.009 accuracy: 88.908%\n",
            "train [35] loss: 0.009 accuracy: 89.165%\n",
            "validation [35] loss: 0.012 accuracy: 84.706%\n",
            "train [36] loss: 0.009 accuracy: 89.628%\n",
            "validation [36] loss: 0.009 accuracy: 89.076%\n",
            "train [37] loss: 0.010 accuracy: 88.534%\n",
            "validation [37] loss: 0.009 accuracy: 89.244%\n",
            "train [38] loss: 0.009 accuracy: 88.765%\n",
            "validation [38] loss: 0.010 accuracy: 88.235%\n",
            "train [39] loss: 0.009 accuracy: 88.723%\n",
            "validation [39] loss: 0.009 accuracy: 88.739%\n",
            "train [40] loss: 0.009 accuracy: 89.186%\n",
            "validation [40] loss: 0.009 accuracy: 90.924%\n",
            "train [41] loss: 0.009 accuracy: 89.480%\n",
            "validation [41] loss: 0.009 accuracy: 89.076%\n",
            "train [42] loss: 0.009 accuracy: 89.459%\n",
            "validation [42] loss: 0.009 accuracy: 90.924%\n",
            "train [43] loss: 0.010 accuracy: 88.576%\n",
            "validation [43] loss: 0.010 accuracy: 88.403%\n",
            "train [44] loss: 0.009 accuracy: 89.270%\n",
            "validation [44] loss: 0.008 accuracy: 91.261%\n",
            "train [45] loss: 0.009 accuracy: 88.996%\n",
            "validation [45] loss: 0.010 accuracy: 89.412%\n",
            "train [46] loss: 0.009 accuracy: 89.123%\n",
            "validation [46] loss: 0.009 accuracy: 89.748%\n",
            "train [47] loss: 0.009 accuracy: 89.228%\n",
            "validation [47] loss: 0.009 accuracy: 90.420%\n",
            "train [48] loss: 0.009 accuracy: 89.228%\n",
            "validation [48] loss: 0.011 accuracy: 88.908%\n",
            "train [49] loss: 0.009 accuracy: 89.060%\n",
            "validation [49] loss: 0.011 accuracy: 89.748%\n",
            "train [50] loss: 0.009 accuracy: 89.354%\n",
            "validation [50] loss: 0.009 accuracy: 89.412%\n",
            "train [51] loss: 0.010 accuracy: 88.639%\n",
            "validation [51] loss: 0.009 accuracy: 89.412%\n",
            "train [52] loss: 0.009 accuracy: 89.417%\n",
            "validation [52] loss: 0.010 accuracy: 89.916%\n",
            "train [53] loss: 0.008 accuracy: 90.406%\n",
            "validation [53] loss: 0.009 accuracy: 90.420%\n",
            "train [54] loss: 0.009 accuracy: 89.564%\n",
            "validation [54] loss: 0.010 accuracy: 89.748%\n",
            "train [55] loss: 0.009 accuracy: 89.438%\n",
            "validation [55] loss: 0.009 accuracy: 90.588%\n",
            "train [56] loss: 0.009 accuracy: 89.375%\n",
            "validation [56] loss: 0.010 accuracy: 88.908%\n",
            "train [57] loss: 0.009 accuracy: 89.333%\n",
            "validation [57] loss: 0.008 accuracy: 89.748%\n",
            "train [58] loss: 0.009 accuracy: 89.480%\n",
            "validation [58] loss: 0.010 accuracy: 89.916%\n",
            "train [59] loss: 0.009 accuracy: 90.090%\n",
            "validation [59] loss: 0.009 accuracy: 91.092%\n",
            "train [60] loss: 0.009 accuracy: 89.838%\n",
            "validation [60] loss: 0.009 accuracy: 90.084%\n",
            "train [61] loss: 0.008 accuracy: 90.343%\n",
            "validation [61] loss: 0.010 accuracy: 88.908%\n",
            "train [62] loss: 0.009 accuracy: 89.901%\n",
            "validation [62] loss: 0.009 accuracy: 91.261%\n",
            "train [63] loss: 0.008 accuracy: 90.448%\n",
            "validation [63] loss: 0.008 accuracy: 91.765%\n",
            "train [64] loss: 0.008 accuracy: 90.680%\n",
            "validation [64] loss: 0.009 accuracy: 89.076%\n",
            "train [65] loss: 0.009 accuracy: 89.901%\n",
            "validation [65] loss: 0.009 accuracy: 89.748%\n",
            "train [66] loss: 0.008 accuracy: 90.343%\n",
            "validation [66] loss: 0.009 accuracy: 92.437%\n",
            "train [67] loss: 0.009 accuracy: 90.069%\n",
            "validation [67] loss: 0.009 accuracy: 90.420%\n",
            "train [68] loss: 0.009 accuracy: 90.301%\n",
            "validation [68] loss: 0.008 accuracy: 90.924%\n",
            "train [69] loss: 0.008 accuracy: 90.364%\n",
            "validation [69] loss: 0.011 accuracy: 86.050%\n",
            "train [70] loss: 0.008 accuracy: 90.280%\n",
            "validation [70] loss: 0.009 accuracy: 90.084%\n",
            "train [71] loss: 0.008 accuracy: 89.943%\n",
            "validation [71] loss: 0.010 accuracy: 88.403%\n",
            "train [72] loss: 0.008 accuracy: 90.637%\n",
            "validation [72] loss: 0.008 accuracy: 91.597%\n",
            "train [73] loss: 0.009 accuracy: 89.964%\n",
            "validation [73] loss: 0.010 accuracy: 89.748%\n",
            "train [74] loss: 0.008 accuracy: 90.680%\n",
            "validation [74] loss: 0.008 accuracy: 90.756%\n",
            "train [75] loss: 0.008 accuracy: 90.722%\n",
            "validation [75] loss: 0.008 accuracy: 92.101%\n",
            "train [76] loss: 0.008 accuracy: 90.574%\n",
            "validation [76] loss: 0.010 accuracy: 89.748%\n",
            "train [77] loss: 0.008 accuracy: 90.133%\n",
            "validation [77] loss: 0.008 accuracy: 91.765%\n",
            "train [78] loss: 0.008 accuracy: 90.448%\n",
            "validation [78] loss: 0.008 accuracy: 91.429%\n",
            "train [79] loss: 0.008 accuracy: 90.406%\n",
            "validation [79] loss: 0.009 accuracy: 88.739%\n",
            "train [80] loss: 0.008 accuracy: 90.553%\n",
            "validation [80] loss: 0.008 accuracy: 89.748%\n",
            "train [81] loss: 0.008 accuracy: 90.827%\n",
            "validation [81] loss: 0.012 accuracy: 87.395%\n",
            "train [82] loss: 0.008 accuracy: 90.427%\n",
            "validation [82] loss: 0.009 accuracy: 91.092%\n",
            "train [83] loss: 0.008 accuracy: 90.764%\n",
            "validation [83] loss: 0.009 accuracy: 89.412%\n",
            "train [84] loss: 0.008 accuracy: 90.322%\n",
            "validation [84] loss: 0.009 accuracy: 91.261%\n",
            "train [85] loss: 0.008 accuracy: 91.353%\n",
            "validation [85] loss: 0.007 accuracy: 92.269%\n",
            "train [86] loss: 0.008 accuracy: 91.079%\n",
            "validation [86] loss: 0.009 accuracy: 90.084%\n",
            "train [87] loss: 0.008 accuracy: 91.121%\n",
            "validation [87] loss: 0.010 accuracy: 90.420%\n",
            "train [88] loss: 0.008 accuracy: 90.364%\n",
            "validation [88] loss: 0.008 accuracy: 91.429%\n",
            "train [89] loss: 0.008 accuracy: 90.890%\n",
            "validation [89] loss: 0.008 accuracy: 89.748%\n",
            "train [90] loss: 0.008 accuracy: 90.974%\n",
            "validation [90] loss: 0.008 accuracy: 91.597%\n",
            "train [91] loss: 0.008 accuracy: 91.248%\n",
            "validation [91] loss: 0.009 accuracy: 89.580%\n",
            "train [92] loss: 0.008 accuracy: 91.248%\n",
            "validation [92] loss: 0.010 accuracy: 88.403%\n",
            "train [93] loss: 0.008 accuracy: 91.121%\n",
            "validation [93] loss: 0.008 accuracy: 90.252%\n",
            "train [94] loss: 0.008 accuracy: 91.227%\n",
            "validation [94] loss: 0.009 accuracy: 90.756%\n",
            "train [95] loss: 0.007 accuracy: 91.121%\n",
            "validation [95] loss: 0.009 accuracy: 91.765%\n",
            "train [96] loss: 0.008 accuracy: 91.163%\n",
            "validation [96] loss: 0.008 accuracy: 91.261%\n",
            "train [97] loss: 0.008 accuracy: 91.206%\n",
            "validation [97] loss: 0.009 accuracy: 91.765%\n",
            "train [98] loss: 0.008 accuracy: 91.227%\n",
            "validation [98] loss: 0.008 accuracy: 90.924%\n",
            "train [99] loss: 0.007 accuracy: 91.395%\n",
            "validation [99] loss: 0.008 accuracy: 91.261%\n",
            "train [100] loss: 0.008 accuracy: 91.437%\n",
            "validation [100] loss: 0.010 accuracy: 88.908%\n"
          ]
        }
      ],
      "source": [
        "fireModel = fireModel.to(device) # Move the model to the GPU or CPU if no GPU are available\n",
        "\n",
        "# Train the model for each epoch\n",
        "for epoch in range(epochs):\n",
        "\t# Training\n",
        "\tfireModel.train(True)\t\t\t# set the model in training mode\n",
        "\ttotalAccuracy = 0.0\t\t\t\t# manually compute accuracy, set 0% as inital accuracy\n",
        "\ttotalLoss = 0.0\t\t\t\t\t\t# manually compute the loss, set 0% as inital loss\n",
        "\tcounter = 0\t\t\t\t\t\t\t\t# count number of data during an epoch (to divide accuracy and loss)\n",
        "\tfor (i, data) in enumerate(trainloader): \t\t\t\t\t\t\t\t\t# for each $i$th batch of data in the trainset\n",
        "\t\tinputs, labels\t= data\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t# put the picture tensor into $inputs$ and labels into $labels$\n",
        "\t\tinputs, labels\t= inputs.to(device), labels.to(device)\t# move inputs and labels to the device (GPU/CPU)\n",
        "\t\toptimizer.zero_grad()\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t# reset the gradient\n",
        "\t\toutputs\t\t\t\t\t= fireModel(inputs)\t\t\t\t\t\t\t\t\t\t\t# Forward pass (predict) the ouputs\n",
        "\t\tloss\t\t\t\t\t\t= criterion(outputs, labels)\t\t\t\t\t\t# Compute the loss\n",
        "\t\tloss.backward()\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t# Compute updates of parameters\n",
        "\t\toptimizer.step()\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t# Update the parameters\n",
        "\t\taccuracy\t\t\t\t= outputs.argmax(dim=1) == labels.argmax(dim=1)\t# Compute the batch accuracy (when outpus match the labels)\n",
        "\t\ttotalAccuracy  += accuracy.int().sum()\t\t\t\t\t\t\t\t\t\t# add the batch accuracy to the total accuracy\n",
        "\t\ttotalLoss \t   += loss.item()\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t# do the same with the loss\n",
        "\t\tcounter\t\t\t\t += len(inputs)\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t# increase the counter\n",
        "\t# Print loss and accuracy\n",
        "\tprint(f'train [{epoch + 1}] loss: {totalLoss / counter:.3f} accuracy: {100 * totalAccuracy / counter:.3f}%')\n",
        "\t# Validate\n",
        "\tfireModel.train(False)\t# Disable training mode (useful when dropout)\n",
        "\twith torch.no_grad():\t\t# Disable autograd (speedup)\n",
        "\t\ttotalAccuracy\t= 0.0\n",
        "\t\ttotalLoss\t\t= 0.0\n",
        "\t\tcounter\t\t\t\t\t= 0\n",
        "\t\tfor (i, data) in enumerate(valloader):\n",
        "\t\t\tinputs, labels\t= data\n",
        "\t\t\tinputs, labels\t= inputs.to(device), labels.to(device)\n",
        "\t\t\toutputs\t\t\t\t\t= fireModel(inputs)\n",
        "\t\t\tloss\t\t\t\t\t\t= criterion(outputs, labels)\n",
        "\t\t\taccuracy\t\t\t\t= outputs.argmax(dim=1) == labels.argmax(dim=1)\n",
        "\t\t\ttotalAccuracy += accuracy.int().sum()\n",
        "\t\t\ttotalLoss\t += loss.item()\n",
        "\t\t\tcounter\t\t\t\t += len(inputs)\n",
        "\t\tprint(f'validation [{epoch + 1}] loss: {totalLoss / counter:.3f} accuracy: {100 * totalAccuracy / counter:.3f}%')\n",
        "\t\ttorch.save(fireModel, f'FireResNet50-{epoch + 1:d}.pt')\n",
        "torch.save(fireModel, 'FireResNet50.pt')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "ri90bCq-VSIe"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\maxgl\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\PIL\\Image.py:945: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Test loss: 0.009 accuracy: 88.552%\n"
          ]
        }
      ],
      "source": [
        "fireModel = torch.load('FireResNet50-97.pt')\n",
        "fireModel.train(False)\n",
        "with torch.no_grad():\n",
        "  totalAccuracy\t= 0.0\n",
        "  totalLoss\t\t= 0.0\n",
        "  counter\t\t\t\t\t= 0\n",
        "  for (i, data) in enumerate(testloader):\n",
        "    inputs, labels = data\n",
        "    inputs, labels = inputs.to(device), labels.to(device)\n",
        "    # forward\n",
        "    outputs = fireModel(inputs)\n",
        "    loss = criterion(outputs, labels)\n",
        "    accuracy\t= outputs.argmax(dim=1) == labels.argmax(dim=1)\n",
        "    totalAccuracy += accuracy.int().sum()\n",
        "    totalLoss += loss.item()\n",
        "    counter += len(inputs)\n",
        "  print(f'Test loss: {totalLoss / counter:.3f} accuracy: {100 * totalAccuracy / counter:.3f}%')"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
