{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Tanguyvans/HackAI/blob/main/comp.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "48mk7EVUwV-H",
        "outputId": "1f5f7895-5474-4b82-d313-ca8d2dc75f15"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch-pruning in /usr/local/lib/python3.10/dist-packages (1.3.7)\n",
            "Requirement already satisfied: torchprofile in /usr/local/lib/python3.10/dist-packages (0.0.4)\n",
            "Requirement already satisfied: torch in /usr/local/lib/python3.10/dist-packages (from torch-pruning) (2.2.1+cu121)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from torch-pruning) (1.25.2)\n",
            "Requirement already satisfied: torchvision>=0.4 in /usr/local/lib/python3.10/dist-packages (from torchprofile) (0.17.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch->torch-pruning) (3.14.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch->torch-pruning) (4.11.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch->torch-pruning) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch->torch-pruning) (3.3)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch->torch-pruning) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch->torch-pruning) (2023.6.0)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->torch-pruning) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->torch-pruning) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->torch-pruning) (12.1.105)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==8.9.2.26 in /usr/local/lib/python3.10/dist-packages (from torch->torch-pruning) (8.9.2.26)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.1.3.1 in /usr/local/lib/python3.10/dist-packages (from torch->torch-pruning) (12.1.3.1)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.0.2.54 in /usr/local/lib/python3.10/dist-packages (from torch->torch-pruning) (11.0.2.54)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.2.106 in /usr/local/lib/python3.10/dist-packages (from torch->torch-pruning) (10.3.2.106)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.4.5.107 in /usr/local/lib/python3.10/dist-packages (from torch->torch-pruning) (11.4.5.107)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.1.0.106 in /usr/local/lib/python3.10/dist-packages (from torch->torch-pruning) (12.1.0.106)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.19.3 in /usr/local/lib/python3.10/dist-packages (from torch->torch-pruning) (2.19.3)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.1.105 in /usr/local/lib/python3.10/dist-packages (from torch->torch-pruning) (12.1.105)\n",
            "Requirement already satisfied: triton==2.2.0 in /usr/local/lib/python3.10/dist-packages (from torch->torch-pruning) (2.2.0)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12 in /usr/local/lib/python3.10/dist-packages (from nvidia-cusolver-cu12==11.4.5.107->torch->torch-pruning) (12.4.127)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.10/dist-packages (from torchvision>=0.4->torchprofile) (9.4.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch->torch-pruning) (2.1.5)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch->torch-pruning) (1.3.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install torch-pruning torchprofile"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "import torch.nn.functional as F\n",
        "import torch\n",
        "import torch_pruning as tp\n",
        "import torchprofile\n",
        "import os\n",
        "import copy\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.optim import *\n",
        "from torch.optim.lr_scheduler import *\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision.datasets as datasets\n",
        "from torchvision.transforms import *\n",
        "from tqdm.auto import tqdm\n",
        "from functools import partial\n",
        "import torchvision.models as models\n",
        "#assert torch.cuda.is_available()"
      ],
      "metadata": {
        "id": "xbeXn4_qwcaa"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# importing shared folder and existing code from HackIA24_input\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gf5vdwuWwh6T",
        "outputId": "7d7280fe-4967-411f-b9a6-58f0aad67e76"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive',force_remount=True)\n",
        "folder='/content/drive/MyDrive/Workshop/' #@param ['/content/drive/MyDrive/Workshop/','/content/drive/MyDrive/IA/UMONS/Workshop/']\n",
        "\n",
        "image_classification_path = f'{folder}2. Image classification'\n",
        "\n",
        "train_dataset_path=   image_classification_path + '/' + 'data'\n",
        "test_dataset_path = image_classification_path + '/' + 'test'\n",
        "\n",
        "best_model_path = image_classification_path + '/' + \"squeeze_final_25.pth\""
      ],
      "metadata": {
        "id": "wCWADxudwnct",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "553f2c6b-e821-40b6-9f92-c592a0e377a0"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Device\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "model = torch.load( best_model_path ).cuda()\n",
        "\n",
        "random_seed = 42\n",
        "\n",
        "# pruning parameters\n",
        "method = \"random\" # choices \"random\", \"l1\", \"lamp\", \"slim\", \"group_norm\", \"group_sl\"\n",
        "speed_up = 2 # speed up ratio based on MACs\n",
        "compression_ratio = 2 # compression ratio based on model size\n",
        "global_pruning = True # if True: global pruning else: local\n",
        "iterative_steps = 400 # pruning steps\n",
        "max_sparsity = 1 # max sparsity\n",
        "\n",
        "num_classes = 3 # to avoid pruning last layer\n",
        "\n",
        "# Fixer le seed pour la reproductibilit√©\n",
        "random.seed(random_seed)\n",
        "np.random.seed(random_seed)\n",
        "torch.manual_seed(random_seed)\n",
        "\n",
        "# training parameters for iterative pruning\n",
        "batchSize\t = 32                                                             # define the batch size\n",
        "trainSplit   = 0.8                                                            # define the ratio of data to use for training\n",
        "testSplit    = 0.1                                                            # define the ratio of data to use for testing\n",
        "validSplit   = 0.1                                                            # the rest is used for validation\n",
        "epochs\t\t = 100                                                            # define the number of epoch\n",
        "criterion    = nn.CrossEntropyLoss()                                          # define the loss function\n",
        "learnRate\t = 0.01                                                           # define the learning rate\n",
        "optimizer    = Adam(model.parameters(), lr=learnRate)                # define the optimizer\n",
        "imgSize      = 224"
      ],
      "metadata": {
        "id": "3ihj6-5nw2PR"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
        "\n",
        "# Device configuration\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Data transformations\n",
        "transform = transforms.Compose([\n",
        "    transforms.RandomResizedCrop(imgSize),\n",
        "    transforms.ToTensor()\n",
        "])\n",
        "\n",
        "target_transform = transforms.Compose([\n",
        "    lambda label: torch.nn.functional.one_hot(torch.tensor(label), num_classes=3).float()\n",
        "])\n",
        "\n",
        "# Dataset\n",
        "dataset = datasets.ImageFolder(train_dataset_path, transform=transform, target_transform=target_transform)\n",
        "\n",
        "# Splitting the dataset\n",
        "trainlen = int(trainSplit * len(dataset))\n",
        "testlen = int(testSplit * len(dataset))\n",
        "validlen = len(dataset) - trainlen - testlen\n",
        "\n",
        "trainset, validset, testset = torch.utils.data.random_split(dataset, [trainlen, validlen, testlen])\n",
        "\n",
        "# DataLoaders\n",
        "trainloader = DataLoader(dataset, batch_size=batchSize, sampler=SubsetRandomSampler(trainset.indices))\n",
        "valloader = DataLoader(dataset, batch_size=batchSize, sampler=SubsetRandomSampler(validset.indices))\n",
        "testloader = DataLoader(dataset, batch_size=batchSize, sampler=SubsetRandomSampler(testset.indices))\n",
        "\n",
        "# Example training loop\n",
        "for inputs, labels in trainloader:\n",
        "    inputs, labels = inputs.to(device), labels.to(device)\n",
        "    # Perform your training operations here"
      ],
      "metadata": {
        "id": "uusSV8gY05Tn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "75a60619-6d3a-41bd-f48d-984682594499"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/PIL/Image.py:996: UserWarning: Palette images with Transparency expressed in bytes should be converted to RGBA images\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Evaluation loop\n",
        "@torch.no_grad()\n",
        "def evaluate(\n",
        "    model: nn.Module,\n",
        "    dataloader: DataLoader,\n",
        "    verbose=True,\n",
        ") -> float:\n",
        "    model.eval()\n",
        "\n",
        "    num_samples = 0\n",
        "    num_correct = 0\n",
        "    loss = 0\n",
        "\n",
        "    for inputs, targets in tqdm(dataloader, desc=\"eval\", leave=False, disable=not verbose):\n",
        "        # Move the data from CPU to GPU\n",
        "        inputs = inputs.to(device)\n",
        "        targets = targets.to(device)\n",
        "\n",
        "        # Inference\n",
        "        outputs = model(inputs)\n",
        "        # Calculate loss\n",
        "        loss += F.cross_entropy(outputs, targets, reduction=\"sum\")\n",
        "        # Convert logits to class indices\n",
        "        outputs = outputs.argmax(dim=1)\n",
        "        # Update metrics\n",
        "        num_samples += targets.size(0)\n",
        "        num_correct += (outputs == targets).sum()\n",
        "    return (num_correct / num_samples * 100).item(), (loss / num_samples).item()\n",
        "\n",
        "# training loop\n",
        "def train(\n",
        "    model: nn.Module,\n",
        "    train_loader: DataLoader,\n",
        "    test_loader: DataLoader,\n",
        "    epochs: int,\n",
        "    lr: int,\n",
        "    # for pruning\n",
        "    weight_decay=5e-4,\n",
        "    pruner=None,\n",
        "    callbacks=None,\n",
        "    save=None,\n",
        "    save_only_state_dict=False,\n",
        ") -> None:\n",
        "\n",
        "    optimizer = torch.optim.SGD(model.parameters(\n",
        "    ), lr=lr, momentum=0.9, weight_decay=weight_decay if pruner is None else 0)\n",
        "    # scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
        "    scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizer, milestones=[40,80,100], gamma=0.1)\n",
        "    criterion = nn.CrossEntropyLoss()\n",
        "    best_acc = -1\n",
        "    best_checkpoint = dict()\n",
        "\n",
        "\n",
        "    for epoch in range(epochs):\n",
        "        model.train()\n",
        "        for inputs, targets in tqdm(train_loader, leave=False):\n",
        "            inputs = inputs.to(device)\n",
        "            targets = targets.to(device)\n",
        "\n",
        "            # Reset the gradients (from the last iteration)\n",
        "            optimizer.zero_grad()\n",
        "\n",
        "            # Forward inference\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "\n",
        "            # Backward propagation\n",
        "            loss.backward()\n",
        "\n",
        "            # Pruner regularize for sparsity learning\n",
        "            if pruner is not None:\n",
        "                pruner.regularize(model)\n",
        "\n",
        "            # Update optimizer\n",
        "            optimizer.step()\n",
        "\n",
        "            if callbacks is not None:\n",
        "                for callback in callbacks:\n",
        "                    callback()\n",
        "\n",
        "        acc, val_loss = evaluate(model, test_loader)\n",
        "        print(\n",
        "            f'Epoch {epoch + 1}/{epochs} | Val acc: {acc:.2f} | Val loss: {val_loss:.4f} | LR: {optimizer.param_groups[0][\"lr\"]:.6f}')\n",
        "\n",
        "        if best_acc < acc:\n",
        "            best_checkpoint['state_dict'] = copy.deepcopy(model.state_dict())\n",
        "            best_acc = acc\n",
        "        # Update LR scheduler\n",
        "        scheduler.step()\n",
        "    model.load_state_dict(best_checkpoint['state_dict'])\n",
        "    if save:\n",
        "        # on veut sauvegarder le meilleur mod√®le\n",
        "        path = os.path.join(os.getcwd(), \"results\", save)\n",
        "        os.makedirs(os.path.dirname(path), exist_ok=True)\n",
        "        if save_only_state_dict:\n",
        "            torch.save(model.state_dict(), path)\n",
        "        else:\n",
        "            torch.save(model, path)\n",
        "    print(f'Best val acc: {best_acc:.2f}')\n",
        "\n",
        "\n",
        "\n",
        "# Pruner\n",
        "# d√©finir le nbre de classses => √©vite de pruner la derni√®re couche\n",
        "def get_pruner(model, example_input):\n",
        "    sparsity_learning = False\n",
        "    if method == \"random\":\n",
        "        imp = tp.importance.RandomImportance()\n",
        "        pruner_entry = partial(tp.pruner.MagnitudePruner, global_pruning=global_pruning)\n",
        "    elif method == \"l1\":\n",
        "        imp = tp.importance.MagnitudeImportance(p=1)\n",
        "        pruner_entry = partial(tp.pruner.MagnitudePruner, global_pruning=global_pruning)\n",
        "    elif method == \"lamp\":\n",
        "        imp = tp.importance.LAMPImportance(p=2)\n",
        "        pruner_entry = partial(tp.pruner.BNScalePruner, global_pruning=global_pruning)\n",
        "    elif method == \"slim\":\n",
        "        sparsity_learning = True\n",
        "        imp = tp.importance.BNScaleImportance()\n",
        "        pruner_entry = partial(tp.pruner.BNScalePruner, reg=1e-5, global_pruning=global_pruning)\n",
        "    elif method == \"group_norm\":\n",
        "        imp = tp.importance.GroupNormImportance(p=2)\n",
        "        pruner_entry = partial(tp.pruner.GroupNormPruner, global_pruning=global_pruning)\n",
        "    elif method == \"group_sl\":\n",
        "        sparsity_learning = True\n",
        "        imp = tp.importance.GroupNormImportance(p=2)\n",
        "        pruner_entry = partial(tp.pruner.GroupNormPruner, reg=1e-5, global_pruning=global_pruning)\n",
        "    else:\n",
        "        raise NotImplementedError\n",
        "\n",
        "    unwrapped_parameters = []\n",
        "    ignored_layers = []\n",
        "    ch_sparsity_dict = {}\n",
        "    # ignore output layers\n",
        "    for m in model.modules():\n",
        "        if isinstance(m, torch.nn.Linear) and m.out_features == num_classes:\n",
        "            ignored_layers.append(m)\n",
        "        elif isinstance(m, torch.nn.modules.conv._ConvNd) and m.out_channels == num_classes:\n",
        "            ignored_layers.append(m)\n",
        "\n",
        "\n",
        "    # Here we fix iterative_steps=200 to prune the model progressively with small steps\n",
        "    # until the required speed up is achieved.\n",
        "    pruner = pruner_entry(\n",
        "        model,\n",
        "        example_input,\n",
        "        importance=imp,\n",
        "        iterative_steps=iterative_steps,\n",
        "        ch_sparsity=1,\n",
        "        ch_sparsity_dict=ch_sparsity_dict,\n",
        "        ignored_layers=ignored_layers,\n",
        "        unwrapped_parameters=unwrapped_parameters,\n",
        "    )\n",
        "    return pruner\n",
        "\n",
        "# pruning jusqu'√† atteindre le speed up voulu\n",
        "def progressive_pruning_speedup(pruner, model, speed_up, example_inputs):\n",
        "    model.eval()\n",
        "    base_ops, _ = tp.utils.count_ops_and_params(\n",
        "        model, example_inputs=example_inputs)\n",
        "    current_speed_up = 1\n",
        "    while current_speed_up < speed_up:\n",
        "        pruner.step(interactive=False)\n",
        "        pruned_ops, _ = tp.utils.count_ops_and_params(\n",
        "            model, example_inputs=example_inputs)\n",
        "        current_speed_up = float(base_ops) / pruned_ops\n",
        "        # print(current_speed_up)\n",
        "        if pruner.current_step == pruner.iterative_steps:\n",
        "            break\n",
        "    return current_speed_up\n",
        "\n",
        "\n",
        "# pruning jusqu'√† atteindre le ratio de compression voulu\n",
        "def progressive_pruning_compression_ratio(pruner, model, compression_ratio, example_inputs):\n",
        "    # compression ratio d√©fini par taille initiale / taille finale\n",
        "    model.eval()\n",
        "    _, base_params = tp.utils.count_ops_and_params(\n",
        "        model, example_inputs=example_inputs)\n",
        "    current_compression_ratio = 1\n",
        "    while current_compression_ratio < compression_ratio:\n",
        "        pruner.step(interactive=False)\n",
        "        _, pruned_params = tp.utils.count_ops_and_params(\n",
        "            model, example_inputs=example_inputs)\n",
        "        current_compression_ratio = float(base_params) / pruned_params\n",
        "        if pruner.current_step == pruner.iterative_steps:\n",
        "            break\n",
        "        # print(current_compression_ratio)\n",
        "    return current_compression_ratio\n",
        "\n",
        "\n",
        "\n",
        "def main():\n",
        "    # Avant pruning\n",
        "    example_input = torch.rand(1, 3, 224, 224).to(device)\n",
        "    start_macs, start_params = tp.utils.count_ops_and_params(model, example_input)\n",
        "    print('----- Avant pruning -----')\n",
        "    print(f'Nombre de MACs = {start_macs/1e6:.3f} M')\n",
        "    print(f'Nombre de param√®tres = {start_params/1e6:.3f} M')\n",
        "    print('')\n",
        "\n",
        "    pruner = get_pruner(model, example_input)\n",
        "    print(f'Pruning method = {method}')\n",
        "\n",
        "    # pruning using compression ratio as objective\n",
        "    # progressive_pruning_compression_ratio(pruner, model, compression_ratio, example_input)\n",
        "\n",
        "    # pruning using speed up ratio as objective (Number of MACs)\n",
        "    progressive_pruning_speedup(pruner, model, speed_up, example_input)\n",
        "    pruned_macs, pruned_params = tp.utils.count_ops_and_params(model, example_input)\n",
        "    print('----- Apr√®s pruning -----')\n",
        "    print(f'Nombre de MACs = {pruned_macs/1e6:.3f} M')\n",
        "    print(f'Nombre de param√®tres = {pruned_params/1e6:.3f} M')\n",
        "    print('')\n",
        "\n",
        "    # Results\n",
        "    print('----- Results before fine tuning -----')\n",
        "    print(f'Params: {start_params/1e6:.2f} M => {pruned_params/1e6:.2f} M')\n",
        "    print(f'MACs: {start_macs/1e6:.2f} M => {pruned_macs/1e6:.2f} M')\n",
        "    print('')"
      ],
      "metadata": {
        "id": "6vsRMObYrTuP"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example_input = torch.rand(1, 3, 224, 224)\n",
        "start_macs, start_params = tp.utils.count_ops_and_params(model.cuda(), example_input.cuda())\n",
        "\n",
        "pruner = get_pruner(model, example_input.cuda())\n",
        "print(f'Pruning method = {method}')\n",
        "\n",
        "# pruning using compression ratio as objective\n",
        "#progressive_pruning_compression_ratio(pruner, model, compression_ratio, example_input)\n",
        "\n",
        "# pruning using speed up ratio as objective (Number of MACs)\n",
        "progressive_pruning_speedup(pruner, model, speed_up, example_input.cuda())\n",
        "pruned_macs, pruned_params = tp.utils.count_ops_and_params(model, example_input.cuda())\n",
        "\n",
        "# Results\n",
        "print('----- Results before fine tuning -----')\n",
        "print(f'Params: {start_params/1e6:.2f} M => {pruned_params/1e6:.2f} M')\n",
        "print(f'MACs: {start_macs/1e6:.2f} M => {pruned_macs/1e6:.2f} M')\n",
        "print('')\n",
        "\n",
        "pruned_model_path = models_path + best_model[ :-4 ] + \"-pruned\" + best_model[ -4: ]\n",
        "print( pruned_model_path )\n",
        "torch.save( model, pruned_model_path )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 396
        },
        "id": "BY0tmBWF1x6J",
        "outputId": "a52820d9-8f97-41a0-9d8f-6612549b8dd7"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/torch_pruning/pruner/algorithms/metapruner.py:87: UserWarning: ch_sparsity is deprecated in v1.3.0. Please use pruning_ratio.\n",
            "  warnings.warn(\"ch_sparsity is deprecated in v1.3.0. Please use pruning_ratio.\")\n",
            "/usr/local/lib/python3.10/dist-packages/torch_pruning/pruner/algorithms/metapruner.py:90: UserWarning: ch_sparsity_dict is deprecated in v1.3.0. Please use pruning_ratio_dict instead.\n",
            "  warnings.warn(\"ch_sparsity_dict is deprecated in v1.3.0. Please use pruning_ratio_dict instead.\")\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pruning method = random\n",
            "----- Results before fine tuning -----\n",
            "Params: 0.72 M => 0.72 M\n",
            "MACs: 269.09 M => 269.09 M\n",
            "\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "name 'best_model' is not defined",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-810edb0324c7>\u001b[0m in \u001b[0;36m<cell line: 20>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     18\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m''\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0msplitted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbest_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplit\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0;34m'.'\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0mpruned_model_path\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodels_path\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbest_model\u001b[0m\u001b[0;34m[\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m4\u001b[0m \u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"-pruned\"\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mbest_model\u001b[0m\u001b[0;34m[\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mpruned_model_path\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'best_model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "train( model.cuda(), trainloader, testloader, epochs, learnRate, pruner = pruner, save = True)"
      ],
      "metadata": {
        "id": "YLGbXHDxRwby"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import sys\n",
        "\n",
        "\n",
        "input_data = torch.rand(1, 3, 224, 224).to(device)\n",
        "benchmark( model, input_data )"
      ],
      "metadata": {
        "id": "nlbrnd6H14G0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}